@article{tversky1981framing,
  title={The framing of decisions and the psychology of choice},
  author={Tversky, Amos and Kahneman, Daniel},
  journal={science},
  volume={211},
  number={4481},
  pages={453--458},
  year={1981},
  publisher={American Association for the Advancement of Science}
}

@article{jacowitz1995measures,
  title={Measures of anchoring in estimation tasks},
  author={Jacowitz, Karen E and Kahneman, Daniel},
  journal={Personality and Social Psychology Bulletin},
  volume={21},
  number={11},
  pages={1161--1166},
  year={1995},
  publisher={Sage Publications Sage CA: Thousand Oaks, CA}
}

@article{maxwell2015suffering,
  title={Is psychology suffering from a replication crisis? What does “failure to replicate” really mean?},
  author={Maxwell, Scott E and Lau, Michael Y and Howard, George S},
  journal={American Psychologist},
  volume={70},
  number={6},
  pages={487},
  year={2015},
  publisher={American Psychological Association}
}

@article{gilbert2016comment,
  title={Comment on “Estimating the reproducibility of psychological science”},
  author={Gilbert, Daniel T and King, Gary and Pettigrew, Stephen and Wilson, Timothy D},
  journal={Science},
  volume={351},
  number={6277},
  pages={1037--1037},
  year={2016},
  publisher={American Association for the Advancement of Science}
}

@article{baker2016scientists,
  title={1,500 scientists lift the lid on reproducibility},
  author={Baker, Monya},
  journal={Nature News},
  volume={533},
  number={7604},
  pages={452},
  year={2016}
}

@article{ayduk2000regulating,
  title={Regulating the interpersonal self: strategic self-regulation for coping with rejection sensitivity.},
  author={Ayduk, Ozlem and Mendoza-Denton, Rodolfo and Mischel, Walter and Downey, Geraldine and Peake, Philip K and Rodriguez, Monica},
  journal={Journal of personality and social psychology},
  volume={79},
  number={5},
  pages={776},
  year={2000},
  publisher={American Psychological Association}
}

@article{mischel1989delay,
  title={Delay of gratification in children},
  author={Mischel, Walter and Shoda, Yuichi and Rodriguez, Monica I},
  journal={Science},
  volume={244},
  number={4907},
  pages={933--938},
  year={1989},
  publisher={American Association for the Advancement of Science}
}

@article{bushman2018boom,
  title={“Boom, Headshot!”: Violent first-person shooter (FPS) video games that reward headshots train individuals to aim for the head when shooting a realistic firearm},
  author={Bushman, Brad J},
  journal={Aggressive behavior},
  year={2018},
  publisher={Wiley Online Library}
}

@article{cohen1994earth,
  title={The earth is round (p<. 05)},
  author={Cohen, Jacob},
  journal = {American Psychologist},
  volume = {49},
  number = {12},
  pages={997--1003},
  year={1994},
  publisher={American Psychological Association}
}

@article{cohen1962statistical,
  title={The statistical power of abnormal-social psychological research: a review.},
  author={Cohen, Jacob},
  journal={The Journal of Abnormal and Social Psychology},
  volume={65},
  number={3},
  pages={145},
  year={1962},
  publisher={American Psychological Association}
}

@article{sterne2001sifting,
  title={Sifting the evidence—what's wrong with significance tests?},
  author={Sterne, Jonathan AC and Smith, George Davey},
  journal={Physical Therapy},
  volume={81},
  number={8},
  pages={1464--1469},
  year={2001},
  publisher={Oxford University Press}
}

@article{meehl1990summaries,
  title={Why summaries of research on psychological theories are often uninterpretable},
  author={Meehl, Paul E},
  journal={Psychological reports},
  volume={66},
  number={1},
  pages={195--244},
  year={1990},
  publisher={SAGE Publications Sage CA: Los Angeles, CA}
}

@article{begley2015reproducibility,
  title={Reproducibility in science: improving the standard for basic and preclinical research},
  author={Begley, C Glenn and Ioannidis, John PA},
  journal={Circulation research},
  volume={116},
  number={1},
  pages={116--126},
  year={2015},
  publisher={Am Heart Assoc}
}

@article{anderson2001effects,
  title={Effects of violent video games on aggressive behavior, aggressive cognition, aggressive affect, physiological arousal, and prosocial behavior: A meta-analytic review of the scientific literature},
  author={Anderson, Craig A and Bushman, Brad J},
  journal={Psychological science},
  volume={12},
  number={5},
  pages={353--359},
  year={2001},
  publisher={SAGE Publications Sage CA: Los Angeles, CA}
}

@article{ferguson2007good,
  title={The good, the bad and the ugly: A meta-analytic review of positive and negative effects of violent video games},
  author={Ferguson, Christopher John},
  journal={Psychiatric quarterly},
  volume={78},
  number={4},
  pages={309--316},
  year={2007},
  publisher={Springer}
}

@article{makel2012replications,
  title={Replications in psychology research: How often do they really occur?},
  author={Makel, Matthew C and Plucker, Jonathan A and Hegarty, Boyd},
  journal={Perspectives on Psychological Science},
  volume={7},
  number={6},
  pages={537--542},
  year={2012},
  publisher={Sage Publications Sage CA: Los Angeles, CA}
}

@article{ioannidis2005why,
  title={Why most published research findings are false},
  author={Ioannidis, John PA},
  journal={PLoS medicine},
  volume={2},
  number={8},
  pages={e124},
  year={2005},
  publisher={Public Library of Science}
}

@article{pashler2012replicability,
  title={Is the replicability crisis overblown? Three arguments examined},
  author={Pashler, Harold and Harris, Christine R},
  journal={Perspectives on Psychological Science},
  volume={7},
  number={6},
  pages={531--536},
  year={2012},
  publisher={Sage Publications Sage CA: Los Angeles, CA}
}

@article{shapin1984pump,
  title={Pump and circumstance: {Robert Boyle's} literary technology},
  author={Shapin, Steven},
  journal={Social studies of science},
  volume={14},
  number={4},
  pages={481--520},
  year={1984},
  publisher={Sage Publications}
}

@website{srivastava2009making,
  author = {Srivastava, Sanjay},
  title = {Making progress in the hardest science},
  year = {2009},
  url = {https://thehardestscience.com/2009/03/14/making-progress-in-the-hardest-science/},
  urldate = {2018-11-27}
}

@article{benjamin2018effects,
    author = {Benjamin Jr, Arlin and Kepes, Sven and Bushman, Brad J},
    title ={Effects of Weapons on Aggressive Thoughts, Angry Feelings, Hostile Appraisals, and Aggressive Behavior: A Meta-Analytic Review of the Weapons Effect Literature},
    journal = {Personality and Social Psychology Review},
    volume = {22},
    number = {4},
    pages = {347-377},
    year = {2018},
    doi = {10.1177/1088868317725419},
    note ={PMID: 28918699},
    eprint = { https://doi.org/10.1177/1088868317725419},
    abstract = { A landmark 1967 study showed that simply seeing a gun can increase aggression—called the “weapons effect.” Since 1967, many other studies have attempted to replicate and explain the weapons effect. This meta-analysis integrates the findings of weapons effect studies conducted from 1967 to 2017 and uses the General Aggression Model (GAM) to explain the weapons effect. It includes 151 effect-size estimates from 78 independent studies involving 7,668 participants. As predicted by the GAM, our naïve meta-analytic results indicate that the mere presence of weapons increased aggressive thoughts, hostile appraisals, and aggression, suggesting a cognitive route from weapons to aggression. Weapons did not significantly increase angry feelings. Yet, a comprehensive sensitivity analysis indicated that not all naïve mean estimates were robust to the presence of publication bias. In general, these results suggest that the published literature tends to overestimate the weapons effect for some outcomes and moderators. }
}


@article{cetin2016effects,
    author = {Çetin, Yakup and Wai, Jonathan and Altay, Cengiz  and Bushman, Brad J},
    title ={RETRACTED: Effects of Violent Media on Verbal Task Performance in Gifted and General Cohort Children},
    journal = {Gifted Child Quarterly},
    volume = {60},
    number = {4},
    pages = {279--286},
    year = {2016},
    doi = {10.1177/0016986216660382},
    eprint = { https://doi.org/10.1177/0016986216660382},
    abstract = { At the request of the Journal Editor(s) and the Publisher and/or the author(s), the following article has been retracted.Çetin, Y., Wai, J., Altay, C., \& Bushman B. J. (2016). Effects of violent media on verbal task performance in gifted and general cohort children. Gifted Child Quarterly, 60(4), 279-287. doi: 10.1177/0016986216660382Joseph Hilgard, postdoctoral fellow at the Annenberg Public Policy Center at the University of Pennsylvania, contacted the journal with questions regarding the pattern of results and conducted reanalyses of the data that called into question the credibility of the data. Unfortunately, the data collection procedures could not be verified because the author who collected the data (Cengiz Altay) could not be contacted following the attempted coup in Turkey. Therefore, as the integrity of the data could not be confirmed, the journal has determined, and the co-authors have agreed, to retract the study. }
}


@article{benjamin2018weapons,
  title = "RETRACTED: The weapons effect",
  journal = "Current Opinion in Psychology",
  volume = "19",
  pages = "93--97",
  year = "2018",
  note = "Aggression and violence",
  issn = "2352-250X",
  doi = "https://doi.org/10.1016/j.copsyc.2017.04.011",
  author = "Benjamin, Arlin James and Bushman, Brad J",
  abstract = "This article has been retracted: please see Elsevier Policy on Article Withdrawal (https://www.elsevier.com/about/our-business/policies/article-withdrawal). This article has been retracted at the request of the Editor-in-Chief, Michael J. Zvolensky. The authors notified the Editors-in-Chief that this invited review has substantial similarity to a previously published paper in this journal by the same authors: Arlin James Benjamin, Brad J Bushman. The weapons priming effect. Current Opinion in Psychology, Volume 12, 2016, Pages 45-48 doi:10.1016/j.copsyc.2016.05.003. http://www.sciencedirect.com/science/article/pii/S2352250X16300495 One of the co-authors, Dr Brad J Bushman, was the Guest Editor of this “Aggression and Violence” issue. The peer review process for this article was handled by an independent Editor with no involvement by the Guest Editor. Apologies are offered to the readers that this was not detected before publication. The journal is reviewing its procedures for the invitation and editorial handling of submissions to help prevent future cases."
}

@article{whitaker2017retraction,
  author = {{Communication Research Editors}},
  title ={Retraction Notice},
  journal = {Communication Research},
  volume = {44},
  number = {1},
  pages = {144-144},
  year = {2017},
  doi = {10.1177/0093650217690274},
  abstract = { The editors of Communication Research, Drs. Gibbs and Knobloch-Westerwick, wish to issue a retraction of the article entitled ““Boom, Headshot!?”: Effect of Video Game Play and Controller Type on Firing Aim and Accuracy” by Jodi L. Whitaker and Brad J. Bushman.This article was first published online on April 30, 2012 and in print in the October 2014 issue of Communication Research (issue 41, pp. 879-891) as doi:10.1177/0093650212446622. It should be noted that, to ensure impartiality, Dr. Knobloch-Westerwick was not involved in the preparation of this decision, because she is on the faculty at the same institution as the corresponding author. This retraction is in response to inquiries from Drs. Markey (Villanova U) and Elson (Ruhr U Bochum), in agreement with the corresponding author Dr. Bushman. }
}

@article{whitacker2012boom,
    author = {Jodi L. Whitaker and Brad J. Bushman},
    title ={RETRACTED: “Boom, Headshot!”: Effect of Video Game Play and Controller Type on Firing Aim and Accuracy},
    journal = {Communication Research},
    volume = {41},
    number = {7},
    pages = {879-891},
    year = {2012},
    doi = {10.1177/0093650212446622},
    retraction = {The editors of Communication Research, Drs. Gibbs and Knobloch-Westerwick, wish to issue a retraction of the article entitled ““Boom, Headshot!?”: Effect of Video Game Play and Controller Type on Firing Aim and Accuracy” by Jodi L. Whitaker and Brad J. Bushman. This article was first published online on April 30, 2012 and in print in the October 2014 issue of Communication Research (issue 41, pp. 879-891) as doi:10.1177/0093650212446622. It should be noted that, to ensure impartiality, Dr. Knobloch-Westerwick was not involved in the preparation of this decision, because she is on the faculty at the same institution as the corresponding author. This retraction is in response to inquiries from Drs. Markey (Villanova U) and Elson (Ruhr U Bochum), in agreement with the corresponding author Dr. Bushman.  A Committee of Initial Inquiry at Ohio State University recommended retracting this article after being alerted to irregularities in some variables of the data set by Drs. Markey and Elson in January 2015. Unfortunately, the values of the questioned variables could not be confirmed because the original research records were unavailable. In 2016, Drs. Markey and Elson sent their report to Dr. Gibbs, one of the editors of Communication Research, who decided that a retraction was warranted. A replication of the study by Dr. Bushman is in review.}
}

@article{watts2018revisiting,
    author = {Tyler W. Watts and Greg J. Duncan and Haonan Quan},
    title ={Revisiting the Marshmallow Test: A Conceptual Replication Investigating Links Between Early Delay of Gratification and Later Outcomes},
    journal = {Psychological Science},
    volume = {29},
    number = {7},
    pages = {1159-1177},
    year = {2018},
    doi = {10.1177/0956797618761661},
    note ={PMID: 29799765},
    eprint = { https://doi.org/10.1177/0956797618761661},
    abstract = { We replicated and extended Shoda, Mischel, and Peake’s (1990) famous marshmallow study, which showed strong bivariate correlations between a child’s ability to delay gratification just before entering school and both adolescent achievement and socioemotional behaviors. Concentrating on children whose mothers had not completed college, we found that an additional minute waited at age 4 predicted a gain of approximately one tenth of a standard deviation in achievement at age 15. But this bivariate correlation was only half the size of those reported in the original studies and was reduced by two thirds in the presence of controls for family background, early cognitive ability, and the home environment. Most of the variation in adolescent achievement came from being able to wait at least 20 s. Associations between delay time and measures of behavioral outcomes at age 15 were much smaller and rarely statistically significant. }
}


@article{ferguson2007evidence,
  title={Evidence for publication bias in video game violence effects literature: A meta-analytic review},
  author={Ferguson, Christopher J},
  journal={Aggression and Violent behavior},
  volume={12},
  number={4},
  pages={470--482},
  year={2007},
  publisher={Elsevier}
}

@website{jhl2018academic,
  title={Academic Journals Data Sharing Requirements},
  websitetitle={Data Management Services},
  url={http://dms.data.jhu.edu/data-management-resources/plan-research/funders-data-sharing-requirement/academic-journals-and-data-sharing-requirements/},
  publisher={Johns Hopkins Libraries{,
  urldate={2018-11-24}}}}

@website{srivastava2018everything,
  title={Everything is fucked: The syllabus},
  author={Srivastava, Sanjay},
  url={https://thehardestscience.com/2016/08/11/everything-is-fucked-the-syllabus/},
  urldate={2018-11-24}}

@article{fanelli2009many,
  title={How many scientists fabricate and falsify research? A systematic review and meta-analysis of survey data},
  author={Fanelli, Daniele},
  journal={PloS one},
  volume={4},
  number={5},
  pages={e5738},
  year={2009},
  publisher={Public Library of Science}
}

@book{braude2002esp,
  title={ESP and psychokinesis: A philosophical examination},
  author={Braude, Stephen E},
  year={2002},
  publisher={Universal-Publishers}
}

@article{open2012open,
    author = {{Open Science Collaboration}},
    title ={An Open, Large-Scale, Collaborative Effort to Estimate the Reproducibility of Psychological Science},
    journal = {{Perspectives on Psychological Science}},
    volume = {7},
    number = {6},
    pages = {657--660},
    year = {2012},
    doi = {10.1177/1745691612462588},
    note ={PMID: 26168127},
    eprint = {https://doi.org/10.1177/1745691612462588},
    abstract = { Reproducibility is a defining feature of science. However, because of strong incentives for innovation and weak incentives for confirmation, direct replication is rarely practiced or published. The Reproducibility Project is an open, large-scale, collaborative effort to systematically examine the rate and predictors of reproducibility in psychological science. So far, 72 volunteer researchers from 41 institutions have organized to openly and transparently replicate studies published in three prominent psychological journals in 2008. Multiple methods will be used to evaluate the findings, calculate an empirical rate of replication, and investigate factors that predict reproducibility. Whatever the result, a better understanding of reproducibility will ultimately improve confidence in scientific methodology and findings. }
}

@article {open2015estimating,
	author = {{Open Science Collaboration}},
	title = {Estimating the reproducibility of psychological science},
	volume = {349},
	number = {6251},
	year = {2015},
	doi = {10.1126/science.aac4716},
	publisher = {American Association for the Advancement of Science},
	abstract = {One of the central goals in any scientific endeavor is to understand causality. Experiments that seek to demonstrate a cause/effect relation most often manipulate the postulated causal factor. Aarts et al. describe the replication of 100 experiments reported in papers published in 2008 in three high-ranking psychology journals. Assessing whether the replication and the original experiment yielded the same result according to several criteria, they find that about one-third to one-half of the original findings were also observed in the replication study.Science, this issue 10.1126/science.aac4716INTRODUCTIONReproducibility is a defining feature of science, but the extent to which it characterizes current research is unknown. Scientific claims should not gain credence because of the status or authority of their originator but by the replicability of their supporting evidence. Even research of exemplary quality may have irreproducible empirical findings because of random or systematic error.RATIONALEThere is concern about the rate and predictors of reproducibility, but limited evidence. Potentially problematic practices include selective reporting, selective analysis, and insufficient specification of the conditions necessary or sufficient to obtain the results. Direct replication is the attempt to recreate the conditions believed sufficient for obtaining a previously observed finding and is the means of establishing reproducibility of a finding with new data. We conducted a large-scale, collaborative effort to obtain an initial estimate of the reproducibility of psychological science.RESULTSWe conducted replications of 100 experimental and correlational studies published in three psychology journals using high-powered designs and original materials when available. There is no single standard for evaluating replication success. Here, we evaluated reproducibility using significance and P values, effect sizes, subjective assessments of replication teams, and meta-analysis of effect sizes. The mean effect size (r) of the replication effects (Mr = 0.197, SD = 0.257) was half the magnitude of the mean effect size of the original effects (Mr = 0.403, SD = 0.188), representing a substantial decline. Ninety-seven percent of original studies had significant results (P \&lt; .05). Thirty-six percent of replications had significant results; 47\% of original effect sizes were in the 95\% confidence interval of the replication effect size; 39\% of effects were subjectively rated to have replicated the original result; and if no bias in original results is assumed, combining original and replication results left 68\% with statistically significant effects. Correlational tests suggest that replication success was better predicted by the strength of original evidence than by characteristics of the original and replication teams.CONCLUSIONNo single indicator sufficiently describes replication success, and the five indicators examined here are not the only ways to evaluate reproducibility. Nonetheless, collectively these results offer a clear conclusion: A large portion of replications produced weaker evidence for the original findings despite using materials provided by the original authors, review in advance for methodological fidelity, and high statistical power to detect the original effect sizes. Moreover, correlational evidence is consistent with the conclusion that variation in the strength of initial evidence (such as original P value) was more predictive of replication success than variation in the characteristics of the teams conducting the research (such as experience and expertise). The latter factors certainly can influence replication success, but they did not appear to do so here.Reproducibility is not well understood because the incentives for individual scientists prioritize novelty over replication. Innovation is the engine of discovery and is vital for a productive, effective scientific enterprise. However, innovative ideas become old news fast. Journal reviewers and editors may dismiss a new test of a published idea as unoriginal. The claim that {\textquotedblleft}we already know this{\textquotedblright} belies the uncertainty of scientific evidence. Innovation points out paths that are possible; replication points out paths that are likely; progress relies on both. Replication can increase certainty when findings are reproduced and promote innovation when they are not. This project provides accumulating evidence for many findings in psychological research and suggests that there is still more work to do to verify whether we know what we think we know.Original study effect size versus replication effect size (correlation coefficients).Diagonal line represents replication effect size equal to original effect size. Dotted line represents replication effect size of 0. Points below the dotted line were effects in the opposite direction of the original. Density plots are separated by significant (blue) and nonsignificant (red) effects.Reproducibility is a defining feature of science, but the extent to which it characterizes current research is unknown. We conducted replications of 100 experimental and correlational studies published in three psychology journals using high-powered designs and original materials when available. Replication effects were half the magnitude of original effects, representing a substantial decline. Ninety-seven percent of original studies had statistically significant results. Thirty-six percent of replications had statistically significant results; 47\% of original effect sizes were in the 95\% confidence interval of the replication effect size; 39\% of effects were subjectively rated to have replicated the original result; and if no bias in original results is assumed, combining original and replication results left 68\% with statistically significant effects. Correlational tests suggest that replication success was better predicted by the strength of original evidence than by characteristics of the original and replication teams.},
	issn = {0036-8075},
	URL = {http://science.sciencemag.org/content/349/6251/aac4716},
	eprint = {http://science.sciencemag.org/content/349/6251/aac4716.full.pdf},
	journal = {Science}
}

@article{klein2014investigating,
    author = {Klein, Richard A. and Ratliff, Kate A. and Vianello, Michelangelo and Adams, Reginald B. and Bahník, Štěpán and Bernstein, Michael J. and Bocian, Konrad and Brandt, Mark J. and Brooks, Beach and Brumbaugh, Claudia Chloe and Cemalcilar, Zeynep and Chandler, Jesse and Cheong, Winnee and Davis, William E. and Devos, Thierry and Eisner, Matthew and Frankowska, Natalia and Furrow, David and Galliani, Elisa Maria and Hasselman, Fred and Hicks, Joshua A. and Hovermale, James F. and Hunt, S. Jane and Huntsinger, Jeffrey R. and IJzerman, Hans and John, Melissa-Sue and Joy-Gaba, Jennifer A. and Barry Kappes, Heather and Krueger, Lacy E. and Kurtz, Jaime and Levitan, Carmel A. and Mallett, Robyn K. and Morris, Wendy L. and Nelson, Anthony J. and Nier, Jason A. and Packard, Grant and Pilati, Ronaldo and Rutchick, Abraham M. and Schmidt, Kathleen and Skorinko, Jeanine L. and Smith, Robert and Steiner, Troy G. and Storbeck, Justin and Van Swol, Lyn M. and Thompson, Donna and van \‘t Veer, A. E. and Ann Vaughn, Leigh and Vranka, Marek and Wichman, Aaron L. and Woodzicka, Julie A. and Nosek, Brian A.},
    title = {Investigating Variation in Replicability\: A "Many Labs" Replication Project},
    journal = {{Social Psychology}},
    volume = {45},
    number = {3},
    pages = {142-152},
    year = {2014},
    doi = {10.1027/1864-9335/a000178},
    eprint = {https://doi.org/10.1027/1864-9335/a000178},
        abstract = { Although replication is a central tenet of science, direct replications are rare in psychology. This research tested variation in the replicability of 13 classic and contemporary effects across 36 independent samples totaling 6,344 participants. In the aggregate, 10 effects replicated consistently. One effect – imagined contact reducing prejudice – showed weak support for replicability. And two effects – flag priming influencing conservatism and currency priming influencing system justification – did not replicate. We compared whether the conditions such as lab versus online or US versus international sample predicted effect magnitudes. By and large they did not. The results of this small sample of effects suggest that replicability is more dependent on the effect itself than on the sample and setting used to investigate the effect. }
}

@article{earp2015replication,
  title={Replication, falsification, and the crisis of confidence in social psychology},
  author={Earp, Brian D and Trafimow, David},
  journal={Frontiers in Psychology},
  volume={6},
  pages={621},
  year={2015},
  publisher={Frontiers}
}
